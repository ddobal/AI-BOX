---
layout: post
title: "TTS 음색 복제 실험 로그"
date: 2025-12-06
category: "Speech"
tags: [tts, tacotron2, hifigan, voice-clone]
---

짧은 음성 데이터(수 분 이내)만 가지고  
“음색 복제”에 얼마나 근접할 수 있는지 테스트한 실험 로그이다.  
완벽한 복제라기보다는,  
**학습용 + 가능성 확인용 실험**이라고 보면 된다.

---

## 1. 사용 모델

- 텍스트 → Mel-spectrogram: **Tacotron2**
- Mel → Waveform: **HiFiGAN**

완전히 새로 학습한 것은 아니고,  
사전학습된 모델을 기반으로  
일부 레이어를 파인튜닝하는 방식으로 진행했다.

---

## 2. 데이터 준비

- 한 화자의 음성 파일 여러 개를 수집  
- 잡음이 심한 구간 / 너무 긴 구간은 잘라내고 정제
- 텍스트 스크립트와의 alignment는 대략적인 수준으로 맞춤

실제 데이터 정제가 TTS 품질에  
예상보다 훨씬 큰 영향을 주었다.

---

## 3. 학습 과정에서의 문제

- 데이터가 많지 않다 보니  
  오버피팅이 금방 발생하는 느낌이었다.
- 특정 단어 발음이 반복적으로 어색해지는 현상
- 문장이 길어질수록 억양이 불안정해지는 현상

이를 줄이기 위해:

- learning rate를 상당히 낮게 설정
- 에폭 수도 너무 길게 끌고 가지 않도록 주의
- 짧은 문장 위주로 발화 패턴을 익히게 한 뒤  
  점점 긴 문장을 섞는 방식으로 조정했다.

---

## 4. 결과 및 느낌

- 음색 자체는 분명히 비슷한 느낌이 났다.
- 다만, **억양·말투까지 완전히 복제**되었다고 보기에는 부족했다.
- 전화 목소리 정도의 품질을 목표로 한다면,  
  충분히 시도해볼 만한 수준이라는 인상을 받았다.

---

## 5. 정리 및 다음 실험 아이디어

- 데이터 정제의 중요성을 크게 느낀 실험이었다.
- 더 나은 결과를 위해서는
  - 발화 종류 다양화
  - Text normalization
  - Prosody 관련 모델 구조 개선  
  등이 필요해 보인다.

향후에는  
VITS 계열, 스타일 토큰 기반 모델 등도  
비교 실험을 해볼 계획이다.


---
layout: post
title: "기초 분류 모델 비교: 로지스틱 회귀 vs KNN"
date: 2025-12-01
tags: [machine-learning, classification, practice]
---

## 실험 목적

이번 실험의 목표는 기초 분류 모델인 **로지스틱 회귀**와 **K-최근접 이웃(KNN)**을 직접 돌려보고,
둘의 성능과 특성을 비교해보는 것이다. 이론상으로만 알고 있던 내용을
직접 데이터에 적용해보면서 감을 잡는 데 초점을 뒀다.

사용한 데이터는 사이킷런에서 제공하는 간단한 이진 분류용 예제 데이터(예: breast cancer 데이터셋)를 활용했다.

## 실험 설정

- 사용 데이터: scikit-learn 내장 이진 분류 데이터셋  
- 데이터 분할: train 70%, test 30%  
- 전처리: StandardScaler를 이용해 평균 0, 분산 1로 정규화  
- 비교 모델:
  - Logistic Regression (L2 정규화, 기본 설정)
  - KNN (k=3, 5, 7 세 가지)

성능 평가는 Accuracy와 F1-score를 함께 확인했다.

## 결과 요약

- 로지스틱 회귀:  
  - 전체적으로 안정적인 성능을 보였고, 과적합 느낌은 거의 없었다.  
- KNN:
  - k=3일 때는 훈련 데이터에 약간 과하게 맞는 경향이 있었고,
    k가 커질수록 결정 경계가 더 완만해지는 느낌을 받았다.

테스트셋 기준으로는 로지스틱 회귀와 KNN(k=5)이 비슷한 정확도를 보였고,
데이터가 그리 복잡하지 않아서 단순한 모델도 충분히 잘 작동한다는 걸 느꼈다.

## 느낀 점

앞으로 복잡한 딥러닝 모델로 가기 전에,
이런 기초 분류 모델들만으로도 꽤 많은 문제를 풀 수 있다는 걸 다시 확인했다.
또, 성능이 비슷할 경우에는 해석이 쉬운 모델(로지스틱 회귀)이 오히려 더 유리할 수 있겠다는 생각도 들었다.
